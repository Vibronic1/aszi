# Лабораторная работа 1

## Описание

Данная лабораторная работа направлена на исследование устойчивости классификационных моделей глубокого обучения к атакам уклонения. В ходе выполнения работы будет проведено обучение моделей на датасетах MNIST и CIFAR-10, а также оценка их устойчивости к атакам FGSM (Fast Gradient Sign Method) и DeepFool.

## Цель работы

Цель лабораторной работы — реализовать и протестировать атаки уклонения на основе белого ящика для моделей глубокого обучения, а также исследовать влияние параметра `eps` на устойчивость моделей.

## Задачи

1. Скопировать проект по ссылке в локальную среду выполнения Jupyter (Google Colab).
2. Создать директорию проекта и выполнить настройку окружения.
3. Импортировать необходимые библиотеки и вспомогательные модули.
4. Загрузить и подготовить датасеты MNIST и CIFAR-10.
5. Реализовать атаки FGSM и DeepFool на классификационных моделях: LeNet, FCNet, Network-in-Network.
6. Оценить устойчивость моделей к атакам.
7. Подготовить отчет, отразив отличия для различных значений параметра `fgsm_eps`.

## Автор

Брестер Андрей Николаевич, группа ББМО-02-23
