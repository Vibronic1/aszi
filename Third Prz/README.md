# Практика 3: Атака Carlini-Wagner (CW) на модели ИИ


## Цель задания:

Изучить одну из наиболее мощных атак на модели ИИ — атаку Carlini-Wagner (CW). Задача —
научиться использовать CW для создания противоречивых примеров и исследовать влияние этой
атаки на обученные модели.

## Задачи:

1. Загрузить ранее обученную модель на датасете MNIST.
2. Изучить теоретические основы атаки Carlini-Wagner.
3. Реализовать атаку CW с помощью фреймворка Foolbox.
4. Оценить точность модели на противоречивых примерах и сравнить с результатами на обычных данных.

## Выполнение:

Выполнение работы было произведено в Google Colab - https://drive.google.com/file/d/1kt_Xh7stimSPW6N-iWsLs_rWsJXNbqvd/view?usp=sharing

## Вывод:

Точность модели на примерах, атакованных методом Carlini-Wagner (CW), значительно снизилась, достигая практически 0% при силе атаки (эпсилон 0.01) и трех шагах оптимизации. 

Для сравнения, на чистых данных модель демонстрировала точность 97%. Это подчеркивает критическую уязвимость модели перед целенаправленными искажениями, даже минимальными. 

Необходимы дальнейшие исследования методов повышения устойчивости модели и защиты от атак, чтобы обеспечить надежность в реальных приложениях.

## Автор

Брестер Андрей Николаевич, группа ББМО-02-23